{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How to load our images\n",
    "### 1.1 MNIST-like load_data function\n",
    "### 1.2 ImageDataGenerator\n",
    "### 1.3 Dataframes\n",
    "\n",
    "## 2. MNIST\n",
    "## 3. Data augmentation\n",
    "## 4. Pre-trained neural networks\n",
    "## 5. RGB or grayscale\n",
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying album covers to genres\n",
    "\n",
    "In the project we try to classify album covers to genres. The dataset has 5022 pictures, sepreated in five categories. The categories are Rock, Pop, Electronic, Jazz and HipHop. One of the challenges of classifying album covers is that there is no systematic which can be applied on covers. For example when we try to classify a picture as dog or cat, we humans can clearly se the difference. And the machine learning algorithm can try to detected shapes that are common for cats and dogs. But when humans look at an album cover, provided that they don't have any prior knowledge, it's classify an album cover. That first thought about the dataset leads to an early thesis that we probalby need an pre-trained neural network for solving this task appropriate.\n",
    "Our approach is to start with traditional machine learning methods, like using an convolutional neural network inspired by the architecture used for classifying handwritten didgets from MNIST. \n",
    "After that we have an baseline for comparing with other methods and possible improvements. Before we look at the different approaches, we will look at how we load the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some comfort functions\n",
    "\n",
    "The cells below will import all needed libraries and also test if the systme is set up correctly. We don't need to duplicate the imports. We just import once before we run other cells with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# keras\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.applications import VGG16\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "# sci kit learm\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import ImageChops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.2.0\n",
      "Keras Version: 2.3.0-tf\n",
      "\n",
      "Python 3.8.5 (default, Sep  5 2020, 10:50:12) \n",
      "[GCC 10.2.0]\n",
      "Pandas 1.0.5\n",
      "Scikit-Learn 0.23.1\n",
      "WARNING:tensorflow:From <ipython-input-2-86f9a4b4bc68>:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How to load images\n",
    "\n",
    "The dataset consists out of 5022 images seperated in the five categories Rock, Pop, Electronic, Jazz and HipHop.\n",
    "For each category exists one folder with the associated images. We use three different approaches to load the data.\n",
    "Our first approach is inspired by the MNIST dataset and we wrote our own `load_data` function. The second approach is the use of an `ImageDataGenerator` that needs a specific directory structure. And the last one is to use dataframes, which are csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 MNIST-like load_data function\n",
    "\n",
    "In the MNIST example the data is loades via `load_data()` function, which returns two tuple with training and test data. This function is imitated by our `load_data()` function.\n",
    "We define a function that goes through the specified path, converts the images to arrays and then appends them to the array $X$. Also it appends the class of the index to the array $y$. Then we use the Scikit-learn function train_test_split to split $X$ and $y$ into $X_{train}$, $X_{test}$, $y_{train}$, $y_{test}$ and return these variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]      4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# define some useful constants\n",
    "DATA_PATH = './data/covers_original/'\n",
    "CATEGORIES = ['electronic', 'hiphop', 'jazz', 'pop', 'rock']\n",
    "IMG_SIZE = 150\n",
    "CATEGORIES_SIZE = 5\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.2\n",
    "\n",
    "# define a function that creates the dataset\n",
    "def load_data():\n",
    "    X = []\n",
    "    y = []\n",
    "    # training data\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATA_PATH, category) # '../data/covers_original/<category>'\n",
    "        cn = CATEGORIES.index(category) # get index of class name (e.g. 'electronic' => 0, 'rock' => 4)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img = load_img(os.path.join(path, img), target_size=(IMG_SIZE, IMG_SIZE))\n",
    "                img_as_array = img_to_array(img)\n",
    "                X.append(img_as_array)\n",
    "                y.append(cn)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    X = np.array(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_PERC)\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "# test tuple\n",
    "#print(X_train[0][0][0], \"    \", y_train[0])\n",
    "# reshape and normalize the data\n",
    "X_train = X_train.reshape((4000, IMG_SIZE, IMG_SIZE, 3))\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.reshape((1000, IMG_SIZE, IMG_SIZE, 3))\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# one-hot encode the class labels (0-9)\n",
    "y_train = np_utils.to_categorical(y_train, CATEGORIES_SIZE)\n",
    "y_test = np_utils.to_categorical(y_test, CATEGORIES_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 ImageDataGenerator\n",
    "\n",
    "ImageDataGenerator gives the opportunity to manipulate the images and enlarge our dataset. This plays an important role when the database is to small. The ImageDataGenerator can transform and rotate the images. By applying data augmentation we hope to reduce or avoid overfitting because on small databases models tend to overfitt. That means the model descibes the\n",
    "training and test data well but performs bad on new data. We will see later if this approache is as productive as expected.\n",
    "\n",
    "The ImageDataGenerator needs a specific directory structure. At the root directory it needs three folder called train, test and validate. In every folder there exists an folder for each category. Then the images are split up in these folder. 80% of the data is going to train. 10% is going to test and another 10% to validate.\n",
    "To use the ImageDataGenerator you just user the path to the specific directory.\n",
    "\n",
    "* root\n",
    "    * test\n",
    "        * rock\n",
    "        * pop\n",
    "        * jazz\n",
    "        * electronic\n",
    "        * hiphoop\n",
    "    * train\n",
    "        * rock \n",
    "        * pop ...\n",
    "    * validate\n",
    "        * ...\n",
    "        \n",
    "        \n",
    "For example the training data needs the path `./data/covers/training`. Then the generator will load and manipulate the data before it is processed by the model.\n",
    "\n",
    "``` python\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_gen = training_datagen.flow_from_directory(\n",
    "    './data/covers/training',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DEST = './data/covers'\n",
    "VALIDATION_PERC = 0.1\n",
    "TEST_PERC = 0.1\n",
    "\n",
    "categories = os.listdir(DATA_PATH)\n",
    "\n",
    "# unfortunately this is too slow, removing the directory \n",
    "# using finder or explorer is way faster\n",
    "# remove directory if it already exists (for convenience)\n",
    "# if os.path.exists(DATA_DEST):\n",
    "#     shutil.rmtree(DATA_DEST)\n",
    "        \n",
    "for category in categories:\n",
    "    # set up some paths\n",
    "    oldCategoryPath = os.path.join(DATA_PATH, category)\n",
    "    newCategoryTrainingPath = os.path.join(os.path.join(DATA_DEST, 'training'), category)\n",
    "    newCategoryValidationPath = os.path.join(os.path.join(DATA_DEST, 'validation'), category)\n",
    "    newCategoryTestPath = os.path.join(os.path.join(DATA_DEST, 'test'), category)\n",
    "\n",
    "    # get all files of each category\n",
    "    files = os.listdir(os.path.join(DATA_PATH, category))\n",
    "    \n",
    "    # make a directory for each category\n",
    "    os.makedirs(newCategoryTrainingPath)\n",
    "    os.makedirs(newCategoryValidationPath)\n",
    "    os.makedirs(newCategoryTestPath)\n",
    "    \n",
    "    # for each category, see how far we have to run for training and validation images.\n",
    "    training_end = int((1-(VALIDATION_PERC + TEST_PERC)) * len(files))\n",
    "    validation_end = training_end + int(VALIDATION_PERC * len(files))\n",
    "    test_end = validation_end + int(TEST_PERC * len(files))\n",
    "    \n",
    "    # separate training and validation files\n",
    "    training_files = files[:training_end]\n",
    "    validation_files = files[training_end:validation_end]\n",
    "    test_files = files[validation_end:test_end]\n",
    "    print('Training files:', len(training_files))\n",
    "    print('Validation files:', len(validation_files))\n",
    "    print('Test files:', len(test_files))\n",
    "    \n",
    "    # copy training files to training path\n",
    "    for idx, file in enumerate(training_files):\n",
    "        oldFilePath = os.path.join(oldCategoryPath, file)\n",
    "        if file != '.DS_Store' and os.path.isfile(oldFilePath):\n",
    "#             newFilename = category + '_image_' + str(idx) + '.jpeg'\n",
    "            newFilePath = os.path.join(newCategoryTrainingPath, file)\n",
    "            shutil.copy(oldFilePath, newFilePath)\n",
    "\n",
    "    # copy validation files to validation path\n",
    "    for idx, file in enumerate(validation_files):\n",
    "        oldFilePath = os.path.join(oldCategoryPath, file)\n",
    "        if file != '.DS_Store' and os.path.isfile(oldFilePath):\n",
    "#             newFilename = category + '_image_' + str(idx) + '.jpeg'\n",
    "            newFilePath = os.path.join(newCategoryValidationPath, file)\n",
    "            shutil.copy(oldFilePath, newFilePath)\n",
    "    \n",
    "    # copy validation files to test path\n",
    "    for idx, file in enumerate(test_files):\n",
    "        oldFilePath = os.path.join(oldCategoryPath, file)\n",
    "        if file != '.DS_Store' and os.path.isfile(oldFilePath):\n",
    "#             newFilename = category + '_image_' + str(idx) + '.jpeg'\n",
    "            newFilePath = os.path.join(newCategoryTestPath, file)\n",
    "            shutil.copy(oldFilePath, newFilePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
