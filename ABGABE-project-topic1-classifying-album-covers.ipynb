{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How to load our images\n",
    "### 1.1 MNIST-like load_data function\n",
    "### 1.2 ImageDataGenerator\n",
    "### 1.3 Dataframes\n",
    "\n",
    "## 2. MNIST\n",
    "## 3. Data augmentation\n",
    "## 4. Pre-trained neural networks\n",
    "## 5. RGB or grayscale\n",
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying album covers to genres\n",
    "\n",
    "In this project we try to classify album covers to genres. The dataset has 5022 pictures, separated in five categories. The categories are Rock, Pop, Electronic, Jazz and HipHop. One of the challenges of classifying album covers is that there is no systematic which can be applied on covers. For example when we try to classify a picture as dog or cat, we humans can clearly see the difference. The machine learning algorithm can tries to detected shapes that are common for cats and dogs. But when humans look at an album cover, provided that they don't have any prior knowledge, it's hard to classify an album cover. That first thought about the dataset leads to an early thesis that we probably need a pre-trained neural network for solving this task appropriate. Because a pre-trained neural network brings in knowledge based on previous trainings. \n",
    "Our approach is to start using a convolutional neural network inspired by the architecture used for classifying handwritten digits from MNIST.\n",
    "After that we have a baseline for comparing with other methods and possible improvements. We will also try our best to implement multi-label classification correctly, because some covers belong to more than one category. And then we dive into pre trained neural networks like VGG16 and observe how they perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The cells below import all needed libraries, define all constants and also test if the system is set up correctly. We don't need to duplicate the imports. We just import once before we run other cells with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "# keras\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.applications import VGG16, VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "# sci kit learm\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import ImageChops\n",
    "\n",
    "\n",
    "# Constants\n",
    "\n",
    "IMG_SIZE=150\n",
    "CATEGORIES = ['electronic', 'hiphop', 'jazz', 'pop', 'rock']\n",
    "PERC_TRAIN = 0.8\n",
    "PERC_VALIDATE = 0.1\n",
    "\n",
    "DATA_PATH = './data/covers_original/'\n",
    "CATEGORIES_SIZE = 5\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.2.0\n",
      "Keras Version: 2.3.0-tf\n",
      "\n",
      "Python 3.8.3 (tags/v3.8.3:6f8c832, May 13 2020, 22:37:02) [MSC v.1924 64 bit (AMD64)]\n",
      "Pandas 1.0.5\n",
      "Scikit-Learn 0.23.1\n",
      "WARNING:tensorflow:From <ipython-input-12-86f9a4b4bc68>:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How to load images\n",
    "\n",
    "The dataset consists out of 5022 images seperated in the five categories Rock, Pop, Electronic, Jazz and HipHop.\n",
    "For each category exists one folder with the associated images. We use three different approaches to load the data.\n",
    "Our first approach is inspired by the MNIST dataset and we wrote our own `load_data` function. The second approach is the use of an `ImageDataGenerator` that needs a specific directory structure, which we will create using a function. And the last one is to use dataframes, which we are also going to create with a function and save them as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 MNIST-like load_data function\n",
    "\n",
    "In the MNIST example the data is loaded via a `load_data()` function, which returns two tuples with training and test data. This function is imitated by our `load_data()` function.\n",
    "We define a function that goes through the specified path, converts the images to arrays and then appends them to the array $X$. Also it appends the class of the index to the array $y$. Then we use the Scikit-learn function train_test_split to split $X$ and $y$ into $X_{train}$, $X_{test}$, $y_{train}$, $y_{test}$ and return these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define some useful constants\n",
    "DATA_PATH = './data/covers_original/'\n",
    "CATEGORIES_SIZE = 5\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.2\n",
    "\n",
    "# define a function that creates the dataset\n",
    "def load_data():\n",
    "    X = []\n",
    "    y = []\n",
    "    # training data\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATA_PATH, category) # '../data/covers_original/<category>'\n",
    "        cn = CATEGORIES.index(category) # get index of class name (e.g. 'electronic' => 0, 'rock' => 4)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img = load_img(os.path.join(path, img), target_size=(IMG_SIZE, IMG_SIZE))\n",
    "                img_as_array = img_to_array(img)\n",
    "                X.append(img_as_array)\n",
    "                y.append(cn)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    X = np.array(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_PERC)\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "# define a function that creates the dataset\n",
    "def load_data_grayscale():\n",
    "    X = []\n",
    "    y = []\n",
    "    # training data\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATA_PATH, category) # '../data/covers_original/<category>'\n",
    "        cn = CATEGORIES.index(category) # get index of class name (e.g. 'electronic' => 0, 'rock' => 4)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img = load_img(os.path.join(path, img), target_size=(IMG_SIZE, IMG_SIZE), color_mode=\"grayscale\")\n",
    "                img_as_array = img_to_array(img)\n",
    "                X.append(img_as_array)\n",
    "                y.append(cn)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    X = np.array(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_PERC)\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "# das k√∂nnten wir noch in das Beispiel selbst unten reinnehmen\n",
    "# (X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "# # test tuple\n",
    "# #print(X_train[0][0][0], \"    \", y_train[0])\n",
    "# # reshape and normalize the data\n",
    "# X_train = X_train.reshape((4000, IMG_SIZE, IMG_SIZE, 3))\n",
    "# X_train = X_train.astype('float32') / 255\n",
    "# X_test = X_test.reshape((1000, IMG_SIZE, IMG_SIZE, 3))\n",
    "# X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# # one-hot encode the class labels (0-9)\n",
    "# y_train = np_utils.to_categorical(y_train, CATEGORIES_SIZE)\n",
    "# y_test = np_utils.to_categorical(y_test, CATEGORIES_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 ImageDataGenerator\n",
    "\n",
    "ImageDataGenerator gives the opportunity to manipulate the images and enlarge our dataset. This plays an important role when the dataset is relatively small. The ImageDataGenerator can transform and rotate the images. That is called data augmentation. By applying data augmentation we hope to reduce or avoid overfitting because models tend to overfitting on small datasets. That means the model descibes the training and test data well but performs bad on new data. We will see later if this approach performs better.\n",
    "\n",
    "The ImageDataGenerator needs a specific directory structure. At the root directory it needs three folders called train, test and validate. In every folder there exists another folder for each category. Then the images are split up into these folders. 80% of the data is going to train. 10% is going to test and another 10% to validate.\n",
    "To use the ImageDataGenerator you just use the path to the specific directory.\n",
    "\n",
    "* root\n",
    "    * test\n",
    "        * rock\n",
    "        * pop\n",
    "        * jazz\n",
    "        * electronic\n",
    "        * hiphoop\n",
    "    * train\n",
    "        * rock \n",
    "        * pop ...\n",
    "    * validate\n",
    "        * ...\n",
    "        \n",
    "\n",
    "For example the training data needs the path `./data/covers/training`. Then the generator will load and manipulate the data before it is processed by the model.\n",
    "\n",
    "``` python\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_gen = training_datagen.flow_from_directory(\n",
    "    './data/covers/training',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: 800\n",
      "Validation files: 100\n",
      "Test files: 100\n",
      "Training files: 800\n",
      "Validation files: 100\n",
      "Test files: 100\n",
      "Training files: 800\n",
      "Validation files: 100\n",
      "Test files: 100\n",
      "Training files: 800\n",
      "Validation files: 100\n",
      "Test files: 100\n",
      "Training files: 800\n",
      "Validation files: 100\n",
      "Test files: 100\n"
     ]
    }
   ],
   "source": [
    "DATA_DEST = './data/covers'\n",
    "VALIDATION_PERC = 0.1\n",
    "TEST_PERC = 0.1\n",
    "\n",
    "categories = os.listdir(DATA_PATH)\n",
    "\n",
    "# unfortunately this is too slow, removing the directory \n",
    "# using finder or explorer is way faster\n",
    "# remove directory if it already exists (for convenience)\n",
    "# if os.path.exists(DATA_DEST):\n",
    "#     shutil.rmtree(DATA_DEST)\n",
    "        \n",
    "for category in categories:\n",
    "    # set up some paths\n",
    "    oldCategoryPath = os.path.join(DATA_PATH, category)\n",
    "    newCategoryTrainingPath = os.path.join(os.path.join(DATA_DEST, 'training'), category)\n",
    "    newCategoryValidationPath = os.path.join(os.path.join(DATA_DEST, 'validation'), category)\n",
    "    newCategoryTestPath = os.path.join(os.path.join(DATA_DEST, 'test'), category)\n",
    "\n",
    "    # get all files of each category\n",
    "    files = os.listdir(os.path.join(DATA_PATH, category))\n",
    "    \n",
    "    # make a directory for each category\n",
    "    os.makedirs(newCategoryTrainingPath)\n",
    "    os.makedirs(newCategoryValidationPath)\n",
    "    os.makedirs(newCategoryTestPath)\n",
    "    \n",
    "    # for each category, see how far we have to run for training and validation images.\n",
    "    training_end = int((1-(VALIDATION_PERC + TEST_PERC)) * len(files))\n",
    "    validation_end = training_end + int(VALIDATION_PERC * len(files))\n",
    "    test_end = validation_end + int(TEST_PERC * len(files))\n",
    "    \n",
    "    # separate training and validation files\n",
    "    training_files = files[:training_end]\n",
    "    validation_files = files[training_end:validation_end]\n",
    "    test_files = files[validation_end:test_end]\n",
    "    print('Training files:', len(training_files))\n",
    "    print('Validation files:', len(validation_files))\n",
    "    print('Test files:', len(test_files))\n",
    "    \n",
    "    # copy training files to training path\n",
    "    for idx, file in enumerate(training_files):\n",
    "        oldFilePath = os.path.join(oldCategoryPath, file)\n",
    "        if file != '.DS_Store' and os.path.isfile(oldFilePath):\n",
    "            newFilePath = os.path.join(newCategoryTrainingPath, file)\n",
    "            shutil.copy(oldFilePath, newFilePath)\n",
    "\n",
    "    # copy validation files to validation path\n",
    "    for idx, file in enumerate(validation_files):\n",
    "        oldFilePath = os.path.join(oldCategoryPath, file)\n",
    "        if file != '.DS_Store' and os.path.isfile(oldFilePath):\n",
    "            newFilePath = os.path.join(newCategoryValidationPath, file)\n",
    "            shutil.copy(oldFilePath, newFilePath)\n",
    "    \n",
    "    # copy validation files to test path\n",
    "    for idx, file in enumerate(test_files):\n",
    "        oldFilePath = os.path.join(oldCategoryPath, file)\n",
    "        if file != '.DS_Store' and os.path.isfile(oldFilePath):\n",
    "            newFilePath = os.path.join(newCategoryTestPath, file)\n",
    "            shutil.copy(oldFilePath, newFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataframes\n",
    "\n",
    "A Dataframe is a csv file that we read using pandas and which is used to access the data and give information about the data. The following function generates the dataframe and saves it as a csv file. The file has the rows `src` and `categories` where src is the path of each file and categories is a comma separated string that contains all categories of that specific image.\n",
    "When the dataframe is imported, the ImageDataGenerator can use this file for the augmentation. We don't need to split the data in the directory structure for ImageDataGenerator.\n",
    "\n",
    "### Example \n",
    "\n",
    "|#| src| categories|\n",
    "|---|---|---|\n",
    "|1| electronic\\electronic.1.jpeg|['electronic', 'pop'] |\n",
    "|2|electronic\\electronic.106.jpeg|['electronic']|\n",
    "|10|electronic\\electronic.107.jpeg|['electronic', 'pop', 'rock']|\n",
    "|11|electronic\\electronic.108.jpeg|['electronic', 'pop', 'rock']|\n",
    "|12|electronic\\electronic.109.jpeg|['electronic']|\n",
    "|13|electronic\\electronic.11.jpeg|['electronic', 'rock']|\n",
    "|14|electronic\\electronic.110.jpeg|['electronic', 'rock']|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "60\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "13\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "190\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "58\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "92\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "256\n",
      "235\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "37\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "310\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "278\n",
      "None\n",
      "None\n",
      "89\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "316\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "122\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "222\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "43\n",
      "None\n",
      "57\n",
      "None\n",
      "459\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "9\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "405\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "329\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "219\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "393\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "573\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "542\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "79\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "14\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "404\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "221\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "153\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "537\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "460\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "636\n",
      "211\n",
      "None\n",
      "0\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "509\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "538\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "403\n",
      "None\n",
      "None\n",
      "None\n",
      "200\n",
      "172\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "332\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "541\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "6\n",
      "None\n",
      "None\n",
      "893\n",
      "None\n",
      "None\n",
      "343\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "71\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "223\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "20\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "314\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "268\n",
      "None\n",
      "270\n",
      "None\n",
      "None\n",
      "274\n",
      "286\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "955\n",
      "None\n",
      "308\n",
      "None\n",
      "None\n",
      "None\n",
      "190\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "375\n",
      "381\n",
      "None\n",
      "387\n",
      "None\n",
      "None\n",
      "400\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "89\n",
      "None\n",
      "None\n",
      "408\n",
      "None\n",
      "418\n",
      "420\n",
      "None\n",
      "None\n",
      "423\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "443\n",
      "None\n",
      "559\n",
      "448\n",
      "None\n",
      "449\n",
      "None\n",
      "None\n",
      "457\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "468\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "524\n",
      "527\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "551\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "594\n",
      "None\n",
      "153\n",
      "600\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "624\n",
      "None\n",
      "None\n",
      "626\n",
      "1020\n",
      "959\n",
      "636\n",
      "637\n",
      "None\n",
      "642\n",
      "644\n",
      "659\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "676\n",
      "679\n",
      "None\n",
      "None\n",
      "681\n",
      "None\n",
      "None\n",
      "683\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "697\n",
      "None\n",
      "None\n",
      "699\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "709\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "636\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "740\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1024\n",
      "None\n",
      "None\n",
      "None\n",
      "768\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "809\n",
      "None\n",
      "812\n",
      "None\n",
      "None\n",
      "None\n",
      "835\n",
      "None\n",
      "848\n",
      "None\n",
      "850\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1094\n",
      "None\n",
      "None\n",
      "870\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1051\n",
      "None\n",
      "None\n",
      "890\n",
      "None\n",
      "None\n",
      "None\n",
      "905\n",
      "None\n",
      "None\n",
      "223\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "926\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "932\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1148\n",
      "None\n",
      "None\n",
      "None\n",
      "679\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1085\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "983\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "80\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "969\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "983\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "89\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "247\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1120\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1106\n",
      "None\n",
      "None\n",
      "None\n",
      "952\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "111\n",
      "None\n",
      "268\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "129\n",
      "1060\n",
      "None\n",
      "1070\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "124\n",
      "153\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "158\n",
      "None\n",
      "None\n",
      "None\n",
      "1062\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1297\n",
      "None\n",
      "1038\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "159\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1111\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1014\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1035\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1490\n",
      "190\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1156\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1572\n",
      "1038\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1306\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "210\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1125\n",
      "None\n",
      "681\n",
      "None\n",
      "None\n",
      "223\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "962\n",
      "None\n",
      "1037\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1128\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1011\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1212\n",
      "1277\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "227\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "228\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1079\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1629\n",
      "None\n",
      "None\n",
      "250\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1353\n",
      "None\n",
      "None\n",
      "243\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "247\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1223\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "953\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "250\n",
      "None\n",
      "None\n",
      "None\n",
      "999\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "971\n",
      "251\n",
      "1220\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1679\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "214\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "235\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "247\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "316\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "302\n",
      "None\n",
      "316\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "235\n",
      "971\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "590\n",
      "None\n",
      "972\n",
      "None\n",
      "None\n",
      "388\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1836\n",
      "977\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "421\n",
      "None\n",
      "None\n",
      "None\n",
      "651\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "434\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1843\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "457\n",
      "458\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1920\n",
      "1002\n",
      "475\n",
      "477\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "530\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1875\n",
      "None\n",
      "557\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1103\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "606\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "665\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "691\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1067\n",
      "1068\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1847\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "724\n",
      "727\n",
      "None\n",
      "None\n",
      "733\n",
      "None\n",
      "734\n",
      "None\n",
      "None\n",
      "739\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "767\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1845\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "810\n",
      "812\n",
      "1841\n",
      "None\n",
      "825\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1948\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1113\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1121\n",
      "1943\n",
      "888\n",
      "890\n",
      "None\n",
      "1965\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "905\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2013\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "24\n",
      "None\n",
      "None\n",
      "None\n",
      "939\n",
      "1927\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2050\n",
      "None\n",
      "1864\n",
      "24\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1899\n",
      "19\n",
      "None\n",
      "None\n",
      "2086\n",
      "None\n",
      "2039\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2007\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "23\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2051\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "36\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1207\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1842\n",
      "2019\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1217\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1221\n",
      "19\n",
      "None\n",
      "None\n",
      "1883\n",
      "1850\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1888\n",
      "1870\n",
      "None\n",
      "None\n",
      "None\n",
      "2134\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "54\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "62\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1266\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2059\n",
      "None\n",
      "1267\n",
      "None\n",
      "None\n",
      "None\n",
      "1994\n",
      "None\n",
      "None\n",
      "2034\n",
      "None\n",
      "1278\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "23\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1917\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1897\n",
      "None\n",
      "None\n",
      "2180\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1863\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "87\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1861\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2022\n",
      "None\n",
      "2187\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1885\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "109\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "247\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2235\n",
      "None\n",
      "None\n",
      "None\n",
      "458\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "62\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1880\n",
      "2442\n",
      "None\n",
      "2010\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1851\n",
      "None\n",
      "None\n",
      "2377\n",
      "None\n",
      "None\n",
      "1389\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1408\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1984\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1426\n",
      "None\n",
      "None\n",
      "2172\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2286\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "141\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2209\n",
      "None\n",
      "None\n",
      "2138\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2042\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1936\n",
      "None\n",
      "None\n",
      "None\n",
      "1858\n",
      "None\n",
      "None\n",
      "None\n",
      "2091\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1912\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2088\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2015\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "158\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2094\n",
      "None\n",
      "None\n",
      "109\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1856\n",
      "None\n",
      "None\n",
      "1844\n",
      "None\n",
      "None\n",
      "None\n",
      "2018\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2064\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2124\n",
      "None\n",
      "None\n",
      "None\n",
      "2223\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2073\n",
      "1513\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1944\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1868\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1910\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2025\n",
      "None\n",
      "None\n",
      "2038\n",
      "None\n",
      "None\n",
      "1534\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1958\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "838\n",
      "None\n",
      "None\n",
      "None\n",
      "860\n",
      "None\n",
      "None\n",
      "1843\n",
      "871\n",
      "None\n",
      "882\n",
      "None\n",
      "None\n",
      "941\n",
      "None\n",
      "2\n",
      "None\n",
      "4\n",
      "None\n",
      "None\n",
      "5\n",
      "None\n",
      "None\n",
      "None\n",
      "7\n",
      "None\n",
      "2102\n",
      "10\n",
      "None\n",
      "None\n",
      "11\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "18\n",
      "None\n",
      "19\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "23\n",
      "27\n",
      "None\n",
      "2051\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "44\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "48\n",
      "None\n",
      "None\n",
      "None\n",
      "52\n",
      "2224\n",
      "2235\n",
      "56\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "65\n",
      "None\n",
      "66\n",
      "None\n",
      "None\n",
      "71\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "77\n",
      "2739\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "640\n",
      "None\n",
      "86\n",
      "None\n",
      "89\n",
      "None\n",
      "None\n",
      "93\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "97\n",
      "None\n",
      "2692\n",
      "104\n",
      "None\n",
      "109\n",
      "None\n",
      "541\n",
      "110\n",
      "2412\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2010\n",
      "None\n",
      "129\n",
      "None\n",
      "2480\n",
      "130\n",
      "None\n",
      "131\n",
      "2490\n",
      "None\n",
      "137\n",
      "139\n",
      "None\n",
      "2286\n",
      "None\n",
      "None\n",
      "144\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "152\n",
      "153\n",
      "None\n",
      "None\n",
      "2577\n",
      "155\n",
      "None\n",
      "None\n",
      "None\n",
      "162\n",
      "None\n",
      "165\n",
      "168\n",
      "None\n",
      "None\n",
      "175\n",
      "179\n",
      "None\n",
      "181\n",
      "None\n",
      "None\n",
      "187\n",
      "None\n",
      "None\n",
      "None\n",
      "79\n",
      "191\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "202\n",
      "None\n",
      "None\n",
      "None\n",
      "206\n",
      "None\n",
      "None\n",
      "None\n",
      "213\n",
      "2681\n",
      "214\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "217\n",
      "None\n",
      "219\n",
      "None\n",
      "None\n",
      "None\n",
      "225\n",
      "None\n",
      "227\n",
      "None\n",
      "228\n",
      "None\n",
      "None\n",
      "1841\n",
      "None\n",
      "None\n",
      "236\n",
      "1843\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "243\n",
      "0\n",
      "None\n",
      "246\n",
      "247\n",
      "250\n",
      "None\n",
      "None\n",
      "252\n",
      "253\n",
      "255\n",
      "257\n",
      "259\n",
      "1984\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "270\n",
      "271\n",
      "None\n",
      "None\n",
      "1865\n",
      "274\n",
      "None\n",
      "None\n",
      "275\n",
      "1866\n",
      "2723\n",
      "2747\n",
      "281\n",
      "None\n",
      "None\n",
      "286\n",
      "287\n",
      "None\n",
      "288\n",
      "None\n",
      "None\n",
      "294\n",
      "1872\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "303\n",
      "None\n",
      "None\n",
      "None\n",
      "304\n",
      "None\n",
      "None\n",
      "None\n",
      "308\n",
      "None\n",
      "None\n",
      "None\n",
      "124\n",
      "None\n",
      "1881\n",
      "None\n",
      "323\n",
      "325\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "328\n",
      "None\n",
      "None\n",
      "None\n",
      "335\n",
      "336\n",
      "None\n",
      "341\n",
      "1888\n",
      "350\n",
      "351\n",
      "355\n",
      "None\n",
      "356\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2816\n",
      "361\n",
      "2700\n",
      "None\n",
      "366\n",
      "None\n",
      "1895\n",
      "256\n",
      "None\n",
      "None\n",
      "None\n",
      "375\n",
      "376\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2703\n",
      "None\n",
      "379\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "387\n",
      "2867\n",
      "167\n",
      "388\n",
      "390\n",
      "394\n",
      "None\n",
      "None\n",
      "None\n",
      "399\n",
      "None\n",
      "400\n",
      "None\n",
      "None\n",
      "402\n",
      "None\n",
      "979\n",
      "278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n",
      "406\n",
      "89\n",
      "None\n",
      "None\n",
      "None\n",
      "2758\n",
      "411\n",
      "None\n",
      "1913\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "211\n",
      "422\n",
      "1917\n",
      "423\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "438\n",
      "443\n",
      "446\n",
      "447\n",
      "448\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "450\n",
      "None\n",
      "2716\n",
      "993\n",
      "None\n",
      "None\n",
      "None\n",
      "256\n",
      "458\n",
      "None\n",
      "None\n",
      "None\n",
      "995\n",
      "459\n",
      "None\n",
      "460\n",
      "None\n",
      "996\n",
      "278\n",
      "997\n",
      "466\n",
      "None\n",
      "470\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1936\n",
      "481\n",
      "2825\n",
      "None\n",
      "1004\n",
      "None\n",
      "2698\n",
      "None\n",
      "489\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "343\n",
      "492\n",
      "493\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1941\n",
      "None\n",
      "None\n",
      "2728\n",
      "None\n",
      "509\n",
      "None\n",
      "405\n",
      "1945\n",
      "None\n",
      "1946\n",
      "None\n",
      "1947\n",
      "None\n",
      "522\n",
      "392\n",
      "None\n",
      "None\n",
      "529\n",
      "531\n",
      "2746\n",
      "532\n",
      "533\n",
      "2790\n",
      "1954\n",
      "None\n",
      "None\n",
      "536\n",
      "None\n",
      "541\n",
      "544\n",
      "None\n",
      "546\n",
      "None\n",
      "None\n",
      "None\n",
      "549\n",
      "412\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "554\n",
      "None\n",
      "None\n",
      "2918\n",
      "560\n",
      "561\n",
      "2797\n",
      "None\n",
      "None\n",
      "564\n",
      "None\n",
      "565\n",
      "None\n",
      "None\n",
      "573\n",
      "None\n",
      "None\n",
      "2912\n",
      "None\n",
      "219\n",
      "2912\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "587\n",
      "None\n",
      "None\n",
      "592\n",
      "593\n",
      "None\n",
      "1984\n",
      "598\n",
      "573\n",
      "604\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "606\n",
      "None\n",
      "None\n",
      "609\n",
      "None\n",
      "1989\n",
      "None\n",
      "None\n",
      "None\n",
      "459\n",
      "None\n",
      "79\n",
      "622\n",
      "None\n",
      "None\n",
      "625\n",
      "None\n",
      "627\n",
      "2712\n",
      "629\n",
      "473\n",
      "2754\n",
      "None\n",
      "630\n",
      "None\n",
      "633\n",
      "635\n",
      "636\n",
      "637\n",
      "None\n",
      "639\n",
      "2965\n",
      "None\n",
      "None\n",
      "None\n",
      "1998\n",
      "648\n",
      "652\n",
      "None\n",
      "None\n",
      "657\n",
      "None\n",
      "658\n",
      "495\n",
      "659\n",
      "2846\n",
      "None\n",
      "None\n",
      "2791\n",
      "2004\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "672\n",
      "1054\n",
      "None\n",
      "676\n",
      "None\n",
      "None\n",
      "679\n",
      "680\n",
      "None\n",
      "None\n",
      "None\n",
      "681\n",
      "1057\n",
      "None\n",
      "None\n",
      "2010\n",
      "None\n",
      "None\n",
      "689\n",
      "None\n",
      "None\n",
      "2898\n",
      "None\n",
      "None\n",
      "697\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2714\n",
      "None\n",
      "515\n",
      "702\n",
      "None\n",
      "None\n",
      "None\n",
      "704\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "709\n",
      "711\n",
      "None\n",
      "1073\n",
      "717\n",
      "2772\n",
      "719\n",
      "None\n",
      "None\n",
      "526\n",
      "723\n",
      "725\n",
      "728\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "731\n",
      "2788\n",
      "636\n",
      "None\n",
      "None\n",
      "None\n",
      "2902\n",
      "211\n",
      "None\n",
      "None\n",
      "None\n",
      "2798\n",
      "None\n",
      "738\n",
      "None\n",
      "740\n",
      "742\n",
      "None\n",
      "None\n",
      "749\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2895\n",
      "None\n",
      "2784\n",
      "758\n",
      "759\n",
      "760\n",
      "2041\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1090\n",
      "770\n",
      "772\n",
      "None\n",
      "None\n",
      "779\n",
      "None\n",
      "1893\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "789\n",
      "2051\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2812\n",
      "1101\n",
      "None\n",
      "None\n",
      "2808\n",
      "None\n",
      "None\n",
      "None\n",
      "800\n",
      "None\n",
      "2691\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1841\n",
      "None\n",
      "3067\n",
      "822\n",
      "590\n",
      "None\n",
      "833\n",
      "None\n",
      "835\n",
      "None\n",
      "None\n",
      "840\n",
      "847\n",
      "848\n",
      "None\n",
      "601\n",
      "None\n",
      "None\n",
      "None\n",
      "2079\n",
      "None\n",
      "None\n",
      "862\n",
      "2724\n",
      "863\n",
      "None\n",
      "None\n",
      "865\n",
      "None\n",
      "1115\n",
      "None\n",
      "None\n",
      "873\n",
      "876\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "881\n",
      "None\n",
      "None\n",
      "None\n",
      "1943\n",
      "2696\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "892\n",
      "2792\n",
      "None\n",
      "None\n",
      "2095\n",
      "2769\n",
      "896\n",
      "None\n",
      "None\n",
      "2718\n",
      "343\n",
      "None\n",
      "71\n",
      "None\n",
      "2708\n",
      "None\n",
      "None\n",
      "None\n",
      "1126\n",
      "620\n",
      "None\n",
      "3096\n",
      "None\n",
      "None\n",
      "908\n",
      "2761\n",
      "None\n",
      "None\n",
      "1132\n",
      "916\n",
      "None\n",
      "917\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "922\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2994\n",
      "None\n",
      "None\n",
      "927\n",
      "928\n",
      "929\n",
      "2111\n",
      "932\n",
      "None\n",
      "None\n",
      "3060\n",
      "662\n",
      "None\n",
      "935\n",
      "936\n",
      "None\n",
      "None\n",
      "940\n",
      "1927\n",
      "None\n",
      "None\n",
      "947\n",
      "None\n",
      "None\n",
      "None\n",
      "3\n",
      "None\n",
      "2815\n",
      "None\n",
      "None\n",
      "3022\n",
      "None\n",
      "None\n",
      "673\n",
      "2122\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2124\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1927\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2127\n",
      "None\n",
      "None\n",
      "1152\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "153\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2722\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2952\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1161\n",
      "3028\n",
      "None\n",
      "None\n",
      "3046\n",
      "2143\n",
      "None\n",
      "None\n",
      "2148\n",
      "2924\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2150\n",
      "1943\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2157\n",
      "871\n",
      "460\n",
      "None\n",
      "None\n",
      "None\n",
      "3234\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0\n",
      "None\n",
      "2165\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "838\n",
      "None\n",
      "225\n",
      "None\n",
      "509\n",
      "1174\n",
      "None\n",
      "3075\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2744\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2177\n",
      "None\n",
      "None\n",
      "679\n",
      "None\n",
      "777\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2729\n",
      "None\n",
      "None\n",
      "788\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1202\n",
      "None\n",
      "806\n",
      "2720\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2739\n",
      "None\n",
      "None\n",
      "None\n",
      "2746\n",
      "None\n",
      "537\n",
      "2754\n",
      "1847\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2771\n",
      "None\n",
      "None\n",
      "None\n",
      "1\n",
      "2784\n",
      "None\n",
      "None\n",
      "None\n",
      "13\n",
      "None\n",
      "None\n",
      "2788\n",
      "24\n",
      "None\n",
      "None\n",
      "2796\n",
      "None\n",
      "None\n",
      "35\n",
      "None\n",
      "None\n",
      "None\n",
      "2802\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "57\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2770\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2816\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2830\n",
      "None\n",
      "None\n",
      "None\n",
      "2837\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1984\n",
      "113\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1329\n",
      "None\n",
      "None\n",
      "2846\n",
      "2850\n",
      "2857\n",
      "None\n",
      "None\n",
      "124\n",
      "2872\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "134\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2882\n",
      "None\n",
      "None\n",
      "None\n",
      "112\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2889\n",
      "1842\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "189\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2902\n",
      "2758\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "211\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2918\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "256\n",
      "None\n",
      "None\n",
      "278\n",
      "None\n",
      "None\n",
      "289\n",
      "None\n",
      "299\n",
      "None\n",
      "None\n",
      "None\n",
      "2867\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "310\n",
      "None\n",
      "None\n",
      "None\n",
      "2825\n",
      "None\n",
      "321\n",
      "None\n",
      "None\n",
      "None\n",
      "333\n",
      "None\n",
      "353\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2956\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2964\n",
      "None\n",
      "None\n",
      "None\n",
      "2797\n",
      "None\n",
      "2912\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2990\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "433\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2995\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "976\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "484\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3022\n",
      "3028\n",
      "None\n",
      "2898\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3051\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "526\n",
      "None\n",
      "1882\n",
      "None\n",
      "2965\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3060\n",
      "3067\n",
      "None\n",
      "None\n",
      "3075\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "538\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3081\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "329\n",
      "None\n",
      "559\n",
      "570\n",
      "None\n",
      "None\n",
      "3096\n",
      "None\n",
      "None\n",
      "None\n",
      "2895\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3121\n",
      "None\n",
      "None\n",
      "None\n",
      "1836\n",
      "None\n",
      "611\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3136\n",
      "3143\n",
      "None\n",
      "None\n",
      "620\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "404\n",
      "None\n",
      "None\n",
      "3509\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2994\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3172\n",
      "None\n",
      "None\n",
      "3196\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1920\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3046\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1943\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "460\n",
      "None\n",
      "None\n",
      "1075\n",
      "509\n",
      "None\n",
      "None\n",
      "None\n",
      "755\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1953\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "788\n",
      "797\n",
      "2693\n",
      "None\n",
      "None\n",
      "2695\n",
      "2696\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "827\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1875\n",
      "None\n",
      "None\n",
      "None\n",
      "2697\n",
      "None\n",
      "1103\n",
      "None\n",
      "None\n",
      "2698\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1993\n",
      "2699\n",
      "None\n",
      "None\n",
      "None\n",
      "860\n",
      "None\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "None\n",
      "882\n",
      "893\n",
      "3442\n",
      "None\n",
      "3216\n",
      "901\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2013\n",
      "920\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2022\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "931\n",
      "None\n",
      "2704\n",
      "941\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2039\n",
      "None\n",
      "None\n",
      "1845\n",
      "2059\n",
      "None\n",
      "None\n",
      "None\n",
      "952\n",
      "None\n",
      "None\n",
      "None\n",
      "3400\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2705\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1948\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2708\n",
      "6\n",
      "None\n",
      "2709\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2710\n",
      "None\n",
      "2711\n",
      "None\n",
      "None\n",
      "None\n",
      "8\n",
      "None\n",
      "2712\n",
      "None\n",
      "None\n",
      "10\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "11\n",
      "None\n",
      "None\n",
      "None\n",
      "2716\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1843\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "14\n",
      "None\n",
      "None\n",
      "None\n",
      "15\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2717\n",
      "None\n",
      "16\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "17\n",
      "2718\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2719\n",
      "19\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2721\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2724\n",
      "2007\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "20\n",
      "21\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "22\n",
      "None\n",
      "None\n",
      "None\n",
      "23\n",
      "3346\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "25\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2707\n",
      "3662\n",
      "None\n",
      "2156\n",
      "None\n",
      "26\n",
      "None\n",
      "None\n",
      "27\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3390\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2726\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "29\n",
      "None\n",
      "31\n",
      "2714\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2727\n",
      "None\n",
      "None\n",
      "None\n",
      "32\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "34\n",
      "None\n",
      "None\n",
      "3604\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "42\n",
      "None\n",
      "None\n",
      "None\n",
      "2729\n",
      "332\n",
      "2731\n",
      "None\n",
      "None\n",
      "None\n",
      "43\n",
      "None\n",
      "None\n",
      "None\n",
      "2209\n",
      "None\n",
      "None\n",
      "2732\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "44\n",
      "None\n",
      "2733\n",
      "2734\n",
      "None\n",
      "2217\n",
      "None\n",
      "None\n",
      "122\n",
      "2735\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3496\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2737\n",
      "48\n",
      "None\n",
      "2738\n",
      "None\n",
      "None\n",
      "None\n",
      "50\n",
      "None\n",
      "None\n",
      "2740\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "51\n",
      "2730\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "52\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3570\n",
      "None\n",
      "None\n",
      "55\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "58\n",
      "None\n",
      "None\n",
      "2741\n",
      "59\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2742\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2743\n",
      "None\n",
      "None\n",
      "None\n",
      "2744\n",
      "None\n",
      "None\n",
      "None\n",
      "61\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "63\n",
      "2747\n",
      "None\n",
      "None\n",
      "64\n",
      "Anzahl dupes:  904\n",
      "                                  src       categories\n",
      "0        electronic\\electronic.1.jpeg   electronic,pop\n",
      "1       electronic\\electronic.10.jpeg  electronic,rock\n",
      "2      electronic\\electronic.100.jpeg   electronic,pop\n",
      "3     electronic\\electronic.1000.jpeg   electronic,pop\n",
      "4      electronic\\electronic.101.jpeg   electronic,pop\n",
      "...                               ...              ...\n",
      "4091               rock\\rock.992.jpeg             rock\n",
      "4092               rock\\rock.993.jpeg             rock\n",
      "4093               rock\\rock.994.jpeg             rock\n",
      "4094               rock\\rock.997.jpeg             rock\n",
      "4095               rock\\rock.998.jpeg             rock\n",
      "\n",
      "[4096 rows x 2 columns]\n",
      "                                  src       categories\n",
      "0        electronic\\electronic.1.jpeg   electronic,pop\n",
      "1       electronic\\electronic.10.jpeg  electronic,rock\n",
      "2      electronic\\electronic.100.jpeg   electronic,pop\n",
      "3     electronic\\electronic.1000.jpeg   electronic,pop\n",
      "4      electronic\\electronic.101.jpeg   electronic,pop\n",
      "...                               ...              ...\n",
      "4091               rock\\rock.992.jpeg             rock\n",
      "4092               rock\\rock.993.jpeg             rock\n",
      "4093               rock\\rock.994.jpeg             rock\n",
      "4094               rock\\rock.997.jpeg             rock\n",
      "4095               rock\\rock.998.jpeg             rock\n",
      "\n",
      "[4096 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def equal(im1, im2):\n",
    "    return ImageChops.difference(im1, im2).getbbox() is None\n",
    "\n",
    "def findImg(img, array):\n",
    "    for i, el in enumerate(array):\n",
    "        if (el==img).all():\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def findDictInArray(img, array):\n",
    "    return next((index for (index, d) in enumerate(array) if (d[\"as_array\"] == img).all()), None)\n",
    "\n",
    "# define a function that creates the dataset\n",
    "def load_data():\n",
    "    data = []\n",
    "    dupes = 0\n",
    "    # training data\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATA_PATH, category) # '../data/covers_original/<category>'\n",
    "        cn = CATEGORIES.index(category) # get index of class name (e.g. 'electronic' => 0, 'rock' => 4)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                img_path_rel = os.path.join(category, img)\n",
    "                image = load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "                img_as_array = np.array(img_to_array(image))\n",
    "                # check if we have seen that image before\n",
    "                #idx = findImg(img_as_array, X)\n",
    "                idx = findDictInArray(img_as_array, data)\n",
    "                print(idx)\n",
    "                # if we have seen it already, update only the labels\n",
    "                if not idx is None:\n",
    "                    dupes += 1 # just to see how many duplicates we have\n",
    "                    # sometimes images are duplicate in their own categories too\n",
    "                    if data[idx]['categories'].find(category) == -1:\n",
    "                        data[idx]['categories'] += ',' + category\n",
    "                else:\n",
    "                    data.append({ 'src': img_path_rel, 'as_array': img_as_array, 'categories': category})\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    print('Anzahl dupes: ', dupes)\n",
    "    return pd.DataFrame(data, columns=['src', 'categories'])\n",
    "\n",
    "# save it as a csv file\n",
    "df = load_data()\n",
    "df.to_csv('./data/df.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MNIST adapted to covers\n",
    "\n",
    "We adapted the Code for MNIST dataset. The last layer now has dense of 5 because we decide between 5 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 87616)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                5607488   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 5,661,509\n",
      "Trainable params: 5,661,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 2s 48ms/step - loss: 2.1656 - accuracy: 0.2275 - val_loss: 1.5968 - val_accuracy: 0.2362\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 1.6056 - accuracy: 0.2788 - val_loss: 1.5889 - val_accuracy: 0.2488\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 1.5157 - accuracy: 0.3512 - val_loss: 1.5969 - val_accuracy: 0.2725\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 1.3136 - accuracy: 0.4559 - val_loss: 1.7114 - val_accuracy: 0.2862\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 1.0783 - accuracy: 0.5878 - val_loss: 1.8653 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.8896 - accuracy: 0.6809 - val_loss: 2.1674 - val_accuracy: 0.2738\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.7580 - accuracy: 0.7572 - val_loss: 2.1927 - val_accuracy: 0.2725\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.6948 - accuracy: 0.7819 - val_loss: 2.1983 - val_accuracy: 0.2688\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5853 - accuracy: 0.8156 - val_loss: 2.4904 - val_accuracy: 0.2725\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5445 - accuracy: 0.8294 - val_loss: 2.3609 - val_accuracy: 0.2700\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.2493 - accuracy: 0.2880\n",
      "Test score: 2.2493386268615723\n",
      "Test accuracy: 0.2879999876022339\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "# test tuple\n",
    "#print(X_train[0][0][0], \"    \", y_train[0])\n",
    "# reshape and normalize the data\n",
    "X_train = X_train.reshape((4000, IMG_SIZE, IMG_SIZE, 3))\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.reshape((1000, IMG_SIZE, IMG_SIZE, 3))\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# one-hot encode the class labels (0-9)\n",
    "y_train = np_utils.to_categorical(y_train, CATEGORIES_SIZE)\n",
    "y_test = np_utils.to_categorical(y_test, CATEGORIES_SIZE)\n",
    "\n",
    "\n",
    "# describe model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', strides=(1,1), padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu')) # reduced 1024 to 64 because of OOM Exceptions\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "# compute loss and accuracy on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "train_loss = history_dict['loss']\n",
    "train_acc = history_dict['accuracy']\n",
    "val_loss = history_dict['val_loss']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.title('Training and validation loss and accuracy')\n",
    "plt.plot(epochs, train_loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above we only reach about 0.29 (29%) accuracy. Maybe this is due to images belonging to more than one class (i.e. a cover may belong to both electronic and hiphop). We will try to solve this using dataframes later. First, we try to reduce complexity, because it has ~10.3 million parameters to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Multi-class vs. Multi-label classification & reducing complexity\n",
    "\n",
    "In the MNIST example we had a multi-class classification problem, because every single digit was in exactly one class. But here our problem is a little bit different, because a cover may be assigned to multiple classes at the same time. We found that this should be a multi-label classification instead. Therefore, our first changes to this network are:\n",
    "- using \"sigmoid\" as our activation function instead of softmax\n",
    "- using binary crossentropy instead of categorical crossentropy\n",
    "\n",
    "We are also trying to reduce complexity by using a convolutional layer with 32 filters instead of 64 and using a kernel size of $3 \\times 3$ instead of $5 \\times 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2654272   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 2,664,741\n",
      "Trainable params: 2,664,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 2s 33ms/step - loss: 0.5761 - accuracy: 0.2125 - val_loss: 0.5072 - val_accuracy: 0.2188\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 1s 27ms/step - loss: 0.5053 - accuracy: 0.2841 - val_loss: 0.5068 - val_accuracy: 0.2688\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.4729 - accuracy: 0.3716 - val_loss: 0.5037 - val_accuracy: 0.2825\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.4262 - accuracy: 0.4903 - val_loss: 0.5650 - val_accuracy: 0.2837\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.3768 - accuracy: 0.5781 - val_loss: 0.5597 - val_accuracy: 0.2837\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.3244 - accuracy: 0.6594 - val_loss: 0.6080 - val_accuracy: 0.2837\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.2833 - accuracy: 0.7191 - val_loss: 0.6427 - val_accuracy: 0.2663\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.2511 - accuracy: 0.7531 - val_loss: 0.7681 - val_accuracy: 0.2738\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.2198 - accuracy: 0.8003 - val_loss: 0.7673 - val_accuracy: 0.2925\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.2049 - accuracy: 0.8200 - val_loss: 0.8026 - val_accuracy: 0.2975\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.1866 - accuracy: 0.8303 - val_loss: 0.8175 - val_accuracy: 0.2837\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1788 - accuracy: 0.8406 - val_loss: 0.7819 - val_accuracy: 0.2850\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1678 - accuracy: 0.8469 - val_loss: 0.8227 - val_accuracy: 0.2988\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1597 - accuracy: 0.8503 - val_loss: 0.8885 - val_accuracy: 0.2850\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.1503 - accuracy: 0.8591 - val_loss: 0.8411 - val_accuracy: 0.2900\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1451 - accuracy: 0.8631 - val_loss: 0.8269 - val_accuracy: 0.2937\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.1392 - accuracy: 0.8625 - val_loss: 0.8425 - val_accuracy: 0.2862\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1343 - accuracy: 0.8631 - val_loss: 0.8454 - val_accuracy: 0.2800\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1310 - accuracy: 0.8594 - val_loss: 0.8449 - val_accuracy: 0.2900\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1267 - accuracy: 0.8625 - val_loss: 0.9522 - val_accuracy: 0.3088\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1255 - accuracy: 0.8650 - val_loss: 0.8542 - val_accuracy: 0.2900\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1184 - accuracy: 0.8641 - val_loss: 0.8725 - val_accuracy: 0.2862\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1152 - accuracy: 0.8666 - val_loss: 0.9399 - val_accuracy: 0.2750\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1146 - accuracy: 0.8647 - val_loss: 0.8310 - val_accuracy: 0.2912\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.1095 - accuracy: 0.8659 - val_loss: 0.9503 - val_accuracy: 0.2900\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1055 - accuracy: 0.8656 - val_loss: 0.8600 - val_accuracy: 0.2988\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.1045 - accuracy: 0.8650 - val_loss: 0.9065 - val_accuracy: 0.2837\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.1009 - accuracy: 0.8681 - val_loss: 0.9717 - val_accuracy: 0.3013\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0997 - accuracy: 0.8678 - val_loss: 1.0294 - val_accuracy: 0.3000\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0977 - accuracy: 0.8678 - val_loss: 0.9552 - val_accuracy: 0.3000\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0954 - accuracy: 0.8681 - val_loss: 1.0036 - val_accuracy: 0.3000\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0936 - accuracy: 0.8725 - val_loss: 1.0078 - val_accuracy: 0.2925\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0931 - accuracy: 0.8691 - val_loss: 0.9801 - val_accuracy: 0.2875\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0902 - accuracy: 0.8728 - val_loss: 0.9599 - val_accuracy: 0.2975\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0889 - accuracy: 0.8694 - val_loss: 1.0250 - val_accuracy: 0.3100\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0861 - accuracy: 0.8722 - val_loss: 1.0635 - val_accuracy: 0.2975\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0858 - accuracy: 0.8700 - val_loss: 1.1668 - val_accuracy: 0.3088\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0860 - accuracy: 0.8725 - val_loss: 1.1394 - val_accuracy: 0.2962\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0834 - accuracy: 0.8669 - val_loss: 1.0325 - val_accuracy: 0.3000\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.0831 - accuracy: 0.8681 - val_loss: 1.0578 - val_accuracy: 0.3088\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0817 - accuracy: 0.8788 - val_loss: 1.0044 - val_accuracy: 0.3050\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0817 - accuracy: 0.8700 - val_loss: 1.2518 - val_accuracy: 0.2988\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0815 - accuracy: 0.8719 - val_loss: 1.1886 - val_accuracy: 0.3038\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0824 - accuracy: 0.8731 - val_loss: 1.0745 - val_accuracy: 0.3113\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0807 - accuracy: 0.8741 - val_loss: 0.9464 - val_accuracy: 0.3088\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0783 - accuracy: 0.8766 - val_loss: 1.1603 - val_accuracy: 0.3025\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0770 - accuracy: 0.8775 - val_loss: 1.1718 - val_accuracy: 0.2962\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.0799 - accuracy: 0.8737 - val_loss: 1.2319 - val_accuracy: 0.3025\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0780 - accuracy: 0.8784 - val_loss: 1.1773 - val_accuracy: 0.2937\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0786 - accuracy: 0.8819 - val_loss: 1.2042 - val_accuracy: 0.3100\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0809 - accuracy: 0.8803 - val_loss: 1.0744 - val_accuracy: 0.2988\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.0775 - accuracy: 0.8775 - val_loss: 1.3940 - val_accuracy: 0.2788\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0752 - accuracy: 0.8791 - val_loss: 1.3560 - val_accuracy: 0.2875\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0783 - accuracy: 0.8806 - val_loss: 1.2486 - val_accuracy: 0.3063\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0750 - accuracy: 0.8809 - val_loss: 1.5172 - val_accuracy: 0.2975\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0756 - accuracy: 0.8759 - val_loss: 1.3601 - val_accuracy: 0.3162\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0759 - accuracy: 0.8813 - val_loss: 1.1224 - val_accuracy: 0.3038\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0732 - accuracy: 0.8797 - val_loss: 1.2468 - val_accuracy: 0.3100\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0741 - accuracy: 0.8834 - val_loss: 1.3122 - val_accuracy: 0.2738\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0749 - accuracy: 0.8863 - val_loss: 1.2710 - val_accuracy: 0.2975\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.0747 - accuracy: 0.8816 - val_loss: 1.2863 - val_accuracy: 0.3038\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0747 - accuracy: 0.8831 - val_loss: 1.4257 - val_accuracy: 0.3000\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0742 - accuracy: 0.8800 - val_loss: 1.3158 - val_accuracy: 0.2862\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0734 - accuracy: 0.8816 - val_loss: 1.2553 - val_accuracy: 0.3150\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0735 - accuracy: 0.8838 - val_loss: 1.2568 - val_accuracy: 0.2988\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0733 - accuracy: 0.8838 - val_loss: 1.2437 - val_accuracy: 0.3100\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0730 - accuracy: 0.8822 - val_loss: 1.4164 - val_accuracy: 0.2875\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0731 - accuracy: 0.8853 - val_loss: 1.5126 - val_accuracy: 0.2988\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0732 - accuracy: 0.8847 - val_loss: 1.2682 - val_accuracy: 0.2962\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0749 - accuracy: 0.8841 - val_loss: 1.6748 - val_accuracy: 0.2975\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.0755 - accuracy: 0.8859 - val_loss: 1.3223 - val_accuracy: 0.3150\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0747 - accuracy: 0.8850 - val_loss: 1.3872 - val_accuracy: 0.3125\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.0750 - accuracy: 0.8816 - val_loss: 1.2860 - val_accuracy: 0.3013\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0729 - accuracy: 0.8838 - val_loss: 1.4563 - val_accuracy: 0.3200\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.0733 - accuracy: 0.8841 - val_loss: 1.4537 - val_accuracy: 0.3113\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.0721 - accuracy: 0.8803 - val_loss: 1.4191 - val_accuracy: 0.3075\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 1s 27ms/step - loss: 0.0732 - accuracy: 0.8838 - val_loss: 1.5077 - val_accuracy: 0.3100\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.0748 - accuracy: 0.8834 - val_loss: 1.4254 - val_accuracy: 0.2937\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.0733 - accuracy: 0.8822 - val_loss: 1.3480 - val_accuracy: 0.3125\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0713 - accuracy: 0.8853 - val_loss: 1.5174 - val_accuracy: 0.2925\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.0742 - accuracy: 0.8884 - val_loss: 1.3159 - val_accuracy: 0.2750\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0708 - accuracy: 0.8906 - val_loss: 1.3026 - val_accuracy: 0.2775\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.0719 - accuracy: 0.8881 - val_loss: 1.5118 - val_accuracy: 0.3038\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.0726 - accuracy: 0.8819 - val_loss: 1.5729 - val_accuracy: 0.2950\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.0703 - accuracy: 0.8856 - val_loss: 1.4341 - val_accuracy: 0.3162\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.0722 - accuracy: 0.8847 - val_loss: 1.5099 - val_accuracy: 0.3137\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.0722 - accuracy: 0.8875 - val_loss: 1.7672 - val_accuracy: 0.3075\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0702 - accuracy: 0.8872 - val_loss: 1.7650 - val_accuracy: 0.3237\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.0717 - accuracy: 0.8872 - val_loss: 1.6404 - val_accuracy: 0.3088\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.0712 - accuracy: 0.8872 - val_loss: 1.7984 - val_accuracy: 0.2937\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0715 - accuracy: 0.8866 - val_loss: 1.5926 - val_accuracy: 0.2988\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0710 - accuracy: 0.8913 - val_loss: 1.4567 - val_accuracy: 0.2988\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0715 - accuracy: 0.8869 - val_loss: 1.3864 - val_accuracy: 0.2925\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0706 - accuracy: 0.8872 - val_loss: 1.4869 - val_accuracy: 0.3088\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0699 - accuracy: 0.8884 - val_loss: 1.4772 - val_accuracy: 0.2812\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.0709 - accuracy: 0.8859 - val_loss: 1.4280 - val_accuracy: 0.2937\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.0728 - accuracy: 0.8819 - val_loss: 2.1538 - val_accuracy: 0.2937\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.0702 - accuracy: 0.8853 - val_loss: 1.8471 - val_accuracy: 0.3013\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.0740 - accuracy: 0.8875 - val_loss: 1.5807 - val_accuracy: 0.3025\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 1s 28ms/step - loss: 0.0696 - accuracy: 0.8909 - val_loss: 1.8547 - val_accuracy: 0.3025\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8991 - accuracy: 0.2900\n",
      "Test score: 1.899134635925293\n",
      "Test accuracy: 0.28999999165534973\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "# test tuple\n",
    "#print(X_train[0][0][0], \"    \", y_train[0])\n",
    "# reshape and normalize the data\n",
    "X_train = X_train.reshape((4000, IMG_SIZE, IMG_SIZE, 3))\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.reshape((1000, IMG_SIZE, IMG_SIZE, 3))\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# one-hot encode the class labels (0-9)\n",
    "y_train = np_utils.to_categorical(y_train, CATEGORIES_SIZE)\n",
    "y_test = np_utils.to_categorical(y_test, CATEGORIES_SIZE)\n",
    "\n",
    "# describe model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='valid', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='valid'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "# history = model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_test, y_test)) # das hier d√ºrfte falsch sein, da validation und test data nicht die selben sein sollten\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1, validation_split=0.2)\n",
    "\n",
    "# compute loss and accuracy on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "train_loss = history_dict['loss']\n",
    "train_acc = history_dict['accuracy']\n",
    "val_loss = history_dict['val_loss']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "plt.title('Training and validation loss and accuracy')\n",
    "plt.plot(epochs, train_loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see reducing the complexity has not really affected to our accuracy positively. But we reduced the parameters from $5.6*10^{6}$ to $2.6*10^{6}$ with the same accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Introducing Dropout\n",
    "\n",
    "The next step is to introduce dropout, that should help us to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 43808)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 43808)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                2803776   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 2,814,245\n",
      "Trainable params: 2,814,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 0.7190 - accuracy: 0.1959 - val_loss: 0.6747 - val_accuracy: 0.2113\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5477 - accuracy: 0.1941 - val_loss: 0.6631 - val_accuracy: 0.2013\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5337 - accuracy: 0.2116 - val_loss: 0.6411 - val_accuracy: 0.2087\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5268 - accuracy: 0.2034 - val_loss: 0.6335 - val_accuracy: 0.2037\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5222 - accuracy: 0.2194 - val_loss: 0.6200 - val_accuracy: 0.2062\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5195 - accuracy: 0.2200 - val_loss: 0.6100 - val_accuracy: 0.2075\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 0.5161 - accuracy: 0.2241 - val_loss: 0.6032 - val_accuracy: 0.2037\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.5155 - accuracy: 0.2150 - val_loss: 0.5910 - val_accuracy: 0.2100\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.5138 - accuracy: 0.2147 - val_loss: 0.5866 - val_accuracy: 0.2025\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5121 - accuracy: 0.2184 - val_loss: 0.5693 - val_accuracy: 0.1975\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5101 - accuracy: 0.2188 - val_loss: 0.5603 - val_accuracy: 0.2100\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5092 - accuracy: 0.2288 - val_loss: 0.5499 - val_accuracy: 0.2037\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5071 - accuracy: 0.2272 - val_loss: 0.5467 - val_accuracy: 0.1975\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.5068 - accuracy: 0.2328 - val_loss: 0.5411 - val_accuracy: 0.2037\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5066 - accuracy: 0.2338 - val_loss: 0.5300 - val_accuracy: 0.1975\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.5046 - accuracy: 0.2534 - val_loss: 0.5230 - val_accuracy: 0.2087\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5035 - accuracy: 0.2522 - val_loss: 0.5186 - val_accuracy: 0.2037\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5011 - accuracy: 0.2541 - val_loss: 0.5146 - val_accuracy: 0.2100\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5006 - accuracy: 0.2566 - val_loss: 0.5104 - val_accuracy: 0.2075\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4984 - accuracy: 0.2669 - val_loss: 0.5057 - val_accuracy: 0.1937\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4969 - accuracy: 0.2719 - val_loss: 0.5034 - val_accuracy: 0.2138\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4941 - accuracy: 0.2778 - val_loss: 0.5021 - val_accuracy: 0.2100\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4945 - accuracy: 0.2834 - val_loss: 0.5000 - val_accuracy: 0.2313\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.4913 - accuracy: 0.2947 - val_loss: 0.4998 - val_accuracy: 0.2100\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4900 - accuracy: 0.2953 - val_loss: 0.4990 - val_accuracy: 0.2062\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4900 - accuracy: 0.2994 - val_loss: 0.4980 - val_accuracy: 0.2138\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4873 - accuracy: 0.3153 - val_loss: 0.4970 - val_accuracy: 0.2275\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4846 - accuracy: 0.3200 - val_loss: 0.4983 - val_accuracy: 0.2125\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4844 - accuracy: 0.3122 - val_loss: 0.4965 - val_accuracy: 0.2125\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4828 - accuracy: 0.3106 - val_loss: 0.4959 - val_accuracy: 0.2275\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.4795 - accuracy: 0.3284 - val_loss: 0.4964 - val_accuracy: 0.2412\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4770 - accuracy: 0.3294 - val_loss: 0.4962 - val_accuracy: 0.2150\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4796 - accuracy: 0.3338 - val_loss: 0.4957 - val_accuracy: 0.2275\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.4781 - accuracy: 0.3450 - val_loss: 0.4949 - val_accuracy: 0.2475\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4748 - accuracy: 0.3347 - val_loss: 0.4956 - val_accuracy: 0.2313\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4738 - accuracy: 0.3444 - val_loss: 0.4954 - val_accuracy: 0.2338\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4684 - accuracy: 0.3587 - val_loss: 0.4952 - val_accuracy: 0.2525\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4670 - accuracy: 0.3584 - val_loss: 0.4930 - val_accuracy: 0.2600\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4649 - accuracy: 0.3653 - val_loss: 0.4951 - val_accuracy: 0.2338\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4603 - accuracy: 0.3853 - val_loss: 0.4952 - val_accuracy: 0.2325\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4621 - accuracy: 0.3762 - val_loss: 0.4949 - val_accuracy: 0.2313\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4608 - accuracy: 0.3694 - val_loss: 0.4930 - val_accuracy: 0.2625\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4576 - accuracy: 0.3794 - val_loss: 0.4943 - val_accuracy: 0.2575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4574 - accuracy: 0.3938 - val_loss: 0.4929 - val_accuracy: 0.2488\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4547 - accuracy: 0.4025 - val_loss: 0.4933 - val_accuracy: 0.2537\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4518 - accuracy: 0.4069 - val_loss: 0.4933 - val_accuracy: 0.2625\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4459 - accuracy: 0.4103 - val_loss: 0.4932 - val_accuracy: 0.2600\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4438 - accuracy: 0.4275 - val_loss: 0.4924 - val_accuracy: 0.2400\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4428 - accuracy: 0.4184 - val_loss: 0.4923 - val_accuracy: 0.2550\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4406 - accuracy: 0.4225 - val_loss: 0.4924 - val_accuracy: 0.2450\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4374 - accuracy: 0.4291 - val_loss: 0.4916 - val_accuracy: 0.2637\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 0.4371 - accuracy: 0.4316 - val_loss: 0.4918 - val_accuracy: 0.2637\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4337 - accuracy: 0.4544 - val_loss: 0.4926 - val_accuracy: 0.2587\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4317 - accuracy: 0.4525 - val_loss: 0.4925 - val_accuracy: 0.2637\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4306 - accuracy: 0.4450 - val_loss: 0.4927 - val_accuracy: 0.2675\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4252 - accuracy: 0.4566 - val_loss: 0.4927 - val_accuracy: 0.2575\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4245 - accuracy: 0.4656 - val_loss: 0.4902 - val_accuracy: 0.2700\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4195 - accuracy: 0.4678 - val_loss: 0.4910 - val_accuracy: 0.2612\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4181 - accuracy: 0.4772 - val_loss: 0.4917 - val_accuracy: 0.2625\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4117 - accuracy: 0.4725 - val_loss: 0.4908 - val_accuracy: 0.2675\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4156 - accuracy: 0.4822 - val_loss: 0.4909 - val_accuracy: 0.2750\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4066 - accuracy: 0.4972 - val_loss: 0.4896 - val_accuracy: 0.2800\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4073 - accuracy: 0.4950 - val_loss: 0.4913 - val_accuracy: 0.2663\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4036 - accuracy: 0.5034 - val_loss: 0.4907 - val_accuracy: 0.2637\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4062 - accuracy: 0.4906 - val_loss: 0.4914 - val_accuracy: 0.2713\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.3992 - accuracy: 0.5069 - val_loss: 0.4903 - val_accuracy: 0.2600\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3991 - accuracy: 0.5097 - val_loss: 0.4914 - val_accuracy: 0.2637\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4040 - accuracy: 0.4941 - val_loss: 0.4918 - val_accuracy: 0.2575\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3929 - accuracy: 0.5175 - val_loss: 0.4915 - val_accuracy: 0.2675\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3909 - accuracy: 0.5184 - val_loss: 0.4924 - val_accuracy: 0.2637\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3871 - accuracy: 0.5394 - val_loss: 0.4926 - val_accuracy: 0.2587\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3877 - accuracy: 0.5409 - val_loss: 0.4929 - val_accuracy: 0.2763\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3887 - accuracy: 0.5306 - val_loss: 0.4920 - val_accuracy: 0.2663\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3853 - accuracy: 0.5269 - val_loss: 0.4922 - val_accuracy: 0.2663\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3853 - accuracy: 0.5247 - val_loss: 0.4909 - val_accuracy: 0.2738\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3766 - accuracy: 0.5537 - val_loss: 0.4913 - val_accuracy: 0.2688\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 0.3779 - accuracy: 0.5481 - val_loss: 0.4928 - val_accuracy: 0.2713\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3760 - accuracy: 0.5500 - val_loss: 0.4925 - val_accuracy: 0.2637\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 0.3727 - accuracy: 0.5547 - val_loss: 0.4920 - val_accuracy: 0.2650\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 0.3687 - accuracy: 0.5647 - val_loss: 0.4948 - val_accuracy: 0.2550\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3703 - accuracy: 0.5678 - val_loss: 0.4920 - val_accuracy: 0.2650\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.3720 - accuracy: 0.5638 - val_loss: 0.4939 - val_accuracy: 0.2587\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3665 - accuracy: 0.5616 - val_loss: 0.4909 - val_accuracy: 0.2800\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3644 - accuracy: 0.5722 - val_loss: 0.4940 - val_accuracy: 0.2663\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3590 - accuracy: 0.5825 - val_loss: 0.4947 - val_accuracy: 0.2625\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3627 - accuracy: 0.5713 - val_loss: 0.4957 - val_accuracy: 0.2637\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3625 - accuracy: 0.5809 - val_loss: 0.4950 - val_accuracy: 0.2612\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 0.3575 - accuracy: 0.5856 - val_loss: 0.4948 - val_accuracy: 0.2688\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3553 - accuracy: 0.5800 - val_loss: 0.4936 - val_accuracy: 0.2688\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 0.3529 - accuracy: 0.5969 - val_loss: 0.4952 - val_accuracy: 0.2725\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3541 - accuracy: 0.5919 - val_loss: 0.4973 - val_accuracy: 0.2763\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3526 - accuracy: 0.5888 - val_loss: 0.4963 - val_accuracy: 0.2750\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3537 - accuracy: 0.5962 - val_loss: 0.4979 - val_accuracy: 0.2688\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3507 - accuracy: 0.6034 - val_loss: 0.4964 - val_accuracy: 0.2738\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3499 - accuracy: 0.5913 - val_loss: 0.4977 - val_accuracy: 0.2713\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3465 - accuracy: 0.5984 - val_loss: 0.4992 - val_accuracy: 0.2663\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3495 - accuracy: 0.5978 - val_loss: 0.4979 - val_accuracy: 0.2650\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.3507 - accuracy: 0.5903 - val_loss: 0.4992 - val_accuracy: 0.2688\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.3466 - accuracy: 0.6119 - val_loss: 0.4978 - val_accuracy: 0.2600\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3546 - accuracy: 0.5900 - val_loss: 0.5023 - val_accuracy: 0.2625\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5078 - accuracy: 0.2750\n",
      "Test score: 0.5078437328338623\n",
      "Test accuracy: 0.2750000059604645\n"
     ]
    }
   ],
   "source": [
    "# describe model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1, validation_split=0.2)\n",
    "\n",
    "# compute loss and accuracy on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this did not help to increase our accuracy, instead it even decreased a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Using data augmentation\n",
    "The next step is to use data augmentation. We hope that if we train with a larger set of data, we can improve our accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                5120032   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 5,139,589\n",
      "Trainable params: 5,139,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 0.6379 - accuracy: 0.2150 - val_loss: 0.5120 - val_accuracy: 0.1650\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.5114 - accuracy: 0.2220 - val_loss: 0.5035 - val_accuracy: 0.2300\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 0.5067 - accuracy: 0.2300 - val_loss: 0.4981 - val_accuracy: 0.2350\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.5039 - accuracy: 0.2200 - val_loss: 0.5027 - val_accuracy: 0.2700\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.5027 - accuracy: 0.2205 - val_loss: 0.4987 - val_accuracy: 0.2450\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 19s 195ms/step - loss: 0.5014 - accuracy: 0.2295 - val_loss: 0.4988 - val_accuracy: 0.2400\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 0.5023 - accuracy: 0.2260 - val_loss: 0.5009 - val_accuracy: 0.2650\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 0.5006 - accuracy: 0.2300 - val_loss: 0.4940 - val_accuracy: 0.2450\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.5010 - accuracy: 0.2410 - val_loss: 0.4961 - val_accuracy: 0.2700\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.5016 - accuracy: 0.2235 - val_loss: 0.5034 - val_accuracy: 0.2200\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.4989 - accuracy: 0.2430 - val_loss: 0.4947 - val_accuracy: 0.2600\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.4993 - accuracy: 0.2390 - val_loss: 0.4966 - val_accuracy: 0.2550\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 0.4976 - accuracy: 0.2480 - val_loss: 0.4967 - val_accuracy: 0.2400\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 19s 194ms/step - loss: 0.4997 - accuracy: 0.2410 - val_loss: 0.4982 - val_accuracy: 0.2350\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 19s 195ms/step - loss: 0.4987 - accuracy: 0.2510 - val_loss: 0.4997 - val_accuracy: 0.2600\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.4978 - accuracy: 0.2470 - val_loss: 0.4949 - val_accuracy: 0.2950\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 0.4993 - accuracy: 0.2595 - val_loss: 0.4999 - val_accuracy: 0.2550\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 19s 192ms/step - loss: 0.4981 - accuracy: 0.2485 - val_loss: 0.4995 - val_accuracy: 0.2750\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.4965 - accuracy: 0.2515 - val_loss: 0.4973 - val_accuracy: 0.2300\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.4969 - accuracy: 0.2590 - val_loss: 0.4974 - val_accuracy: 0.2550\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 0.4973 - accuracy: 0.2525 - val_loss: 0.4993 - val_accuracy: 0.2600\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.4994 - accuracy: 0.2510 - val_loss: 0.5004 - val_accuracy: 0.2600\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.4984 - accuracy: 0.2475 - val_loss: 0.4965 - val_accuracy: 0.2550\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.4977 - accuracy: 0.2625 - val_loss: 0.4983 - val_accuracy: 0.2400\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 0.4968 - accuracy: 0.2675 - val_loss: 0.5034 - val_accuracy: 0.2150\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 0.4994 - accuracy: 0.2565 - val_loss: 0.5059 - val_accuracy: 0.2300\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.4982 - accuracy: 0.2370 - val_loss: 0.5009 - val_accuracy: 0.2900\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.4988 - accuracy: 0.2450 - val_loss: 0.5015 - val_accuracy: 0.2950\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.4971 - accuracy: 0.2475 - val_loss: 0.5045 - val_accuracy: 0.2650\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.4975 - accuracy: 0.2525 - val_loss: 0.5010 - val_accuracy: 0.2600\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.4970 - accuracy: 0.2640 - val_loss: 0.4972 - val_accuracy: 0.3500\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 0.4974 - accuracy: 0.2575 - val_loss: 0.5051 - val_accuracy: 0.2000\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.4957 - accuracy: 0.2640 - val_loss: 0.5035 - val_accuracy: 0.2000\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.4956 - accuracy: 0.2620 - val_loss: 0.5038 - val_accuracy: 0.2200\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.4960 - accuracy: 0.2610 - val_loss: 0.5009 - val_accuracy: 0.2650\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 19s 194ms/step - loss: 0.4968 - accuracy: 0.2500 - val_loss: 0.5072 - val_accuracy: 0.2650\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.4961 - accuracy: 0.2650 - val_loss: 0.4945 - val_accuracy: 0.2800\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.4970 - accuracy: 0.2600 - val_loss: 0.5066 - val_accuracy: 0.2350\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 0.4969 - accuracy: 0.2635 - val_loss: 0.4969 - val_accuracy: 0.2650\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 0.4971 - accuracy: 0.2435 - val_loss: 0.5085 - val_accuracy: 0.2450\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.4969 - accuracy: 0.2460 - val_loss: 0.5028 - val_accuracy: 0.2350\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 0.4961 - accuracy: 0.2620 - val_loss: 0.4988 - val_accuracy: 0.2700\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 19s 195ms/step - loss: 0.4970 - accuracy: 0.2620 - val_loss: 0.4973 - val_accuracy: 0.2900\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 0.4965 - accuracy: 0.2560 - val_loss: 0.4905 - val_accuracy: 0.3150\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.4951 - accuracy: 0.2645 - val_loss: 0.4976 - val_accuracy: 0.2900\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.4986 - accuracy: 0.2375 - val_loss: 0.5006 - val_accuracy: 0.2650\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4960 - accuracy: 0.2645 - val_loss: 0.4958 - val_accuracy: 0.2550\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.4949 - accuracy: 0.2695 - val_loss: 0.5081 - val_accuracy: 0.2600\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.4968 - accuracy: 0.2705 - val_loss: 0.4922 - val_accuracy: 0.2850\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.4958 - accuracy: 0.2535 - val_loss: 0.4966 - val_accuracy: 0.2950\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 0.4972 - accuracy: 0.2585 - val_loss: 0.4996 - val_accuracy: 0.2500\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 0.4960 - accuracy: 0.2630 - val_loss: 0.4993 - val_accuracy: 0.2850\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 20s 203ms/step - loss: 0.4948 - accuracy: 0.2605 - val_loss: 0.4922 - val_accuracy: 0.3150\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 0.4960 - accuracy: 0.2610 - val_loss: 0.4950 - val_accuracy: 0.2650\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.4961 - accuracy: 0.2695 - val_loss: 0.5045 - val_accuracy: 0.2150\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.4987 - accuracy: 0.2530 - val_loss: 0.4951 - val_accuracy: 0.2800\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.4964 - accuracy: 0.2615 - val_loss: 0.4938 - val_accuracy: 0.2750\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.4952 - accuracy: 0.2695 - val_loss: 0.5072 - val_accuracy: 0.2350\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.4941 - accuracy: 0.2840 - val_loss: 0.5004 - val_accuracy: 0.2700\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.4950 - accuracy: 0.2730 - val_loss: 0.5131 - val_accuracy: 0.2300\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 0.4941 - accuracy: 0.2780 - val_loss: 0.5005 - val_accuracy: 0.3000\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.4956 - accuracy: 0.2670 - val_loss: 0.4986 - val_accuracy: 0.2800\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.4955 - accuracy: 0.2780 - val_loss: 0.4984 - val_accuracy: 0.2950\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.4978 - accuracy: 0.2740 - val_loss: 0.4967 - val_accuracy: 0.2550\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.4953 - accuracy: 0.2605 - val_loss: 0.5077 - val_accuracy: 0.2400\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.4966 - accuracy: 0.2615 - val_loss: 0.4996 - val_accuracy: 0.2450\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.4986 - accuracy: 0.2580 - val_loss: 0.5208 - val_accuracy: 0.2550\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.4952 - accuracy: 0.2735 - val_loss: 0.5051 - val_accuracy: 0.2350\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.4973 - accuracy: 0.2605 - val_loss: 0.4914 - val_accuracy: 0.3050\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.4968 - accuracy: 0.2650 - val_loss: 0.5071 - val_accuracy: 0.2650\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.4967 - accuracy: 0.2555 - val_loss: 0.4982 - val_accuracy: 0.2350\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.4947 - accuracy: 0.2785 - val_loss: 0.5107 - val_accuracy: 0.2350\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.4967 - accuracy: 0.2640 - val_loss: 0.5051 - val_accuracy: 0.2150\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.4955 - accuracy: 0.2750 - val_loss: 0.4989 - val_accuracy: 0.2850\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.4956 - accuracy: 0.2750 - val_loss: 0.4973 - val_accuracy: 0.2600\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4945 - accuracy: 0.2845 - val_loss: 0.4942 - val_accuracy: 0.2600\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.4943 - accuracy: 0.2765 - val_loss: 0.4963 - val_accuracy: 0.2750\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.4953 - accuracy: 0.2725 - val_loss: 0.4946 - val_accuracy: 0.2800\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.4937 - accuracy: 0.2760 - val_loss: 0.4929 - val_accuracy: 0.3000\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.4958 - accuracy: 0.2800 - val_loss: 0.5029 - val_accuracy: 0.2650\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.4946 - accuracy: 0.2875 - val_loss: 0.5044 - val_accuracy: 0.2550\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4956 - accuracy: 0.2945 - val_loss: 0.4974 - val_accuracy: 0.2550\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4949 - accuracy: 0.2690 - val_loss: 0.4987 - val_accuracy: 0.2850\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.4948 - accuracy: 0.2730 - val_loss: 0.4944 - val_accuracy: 0.2650\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.4960 - accuracy: 0.2715 - val_loss: 0.4947 - val_accuracy: 0.3150\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.4954 - accuracy: 0.2675 - val_loss: 0.4972 - val_accuracy: 0.2750\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.4987 - accuracy: 0.2360 - val_loss: 0.4942 - val_accuracy: 0.2500\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.4943 - accuracy: 0.2800 - val_loss: 0.4912 - val_accuracy: 0.2850\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.4933 - accuracy: 0.2780 - val_loss: 0.6032 - val_accuracy: 0.2150\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.4976 - accuracy: 0.2810 - val_loss: 0.4988 - val_accuracy: 0.2450\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.4959 - accuracy: 0.2610 - val_loss: 0.4914 - val_accuracy: 0.3050\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4958 - accuracy: 0.2755 - val_loss: 0.4935 - val_accuracy: 0.2900\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.4955 - accuracy: 0.2665 - val_loss: 0.4887 - val_accuracy: 0.2650\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4960 - accuracy: 0.2690 - val_loss: 0.4994 - val_accuracy: 0.3050\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.4960 - accuracy: 0.2670 - val_loss: 0.5105 - val_accuracy: 0.2900\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.4940 - accuracy: 0.2635 - val_loss: 0.4996 - val_accuracy: 0.2500\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 0.4926 - accuracy: 0.2950 - val_loss: 0.5087 - val_accuracy: 0.2950\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.4954 - accuracy: 0.2625 - val_loss: 0.5040 - val_accuracy: 0.2550\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.4946 - accuracy: 0.2720 - val_loss: 0.5010 - val_accuracy: 0.2950\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.4966 - accuracy: 0.2625 - val_loss: 0.4907 - val_accuracy: 0.3100\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.4918 - accuracy: 0.2860\n",
      "Test score: 0.4917795658111572\n",
      "Test accuracy: 0.28600001335144043\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "IMG_SIZE = 200\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_gen = training_datagen.flow_from_directory(\n",
    "    './data/covers/training',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_directory(\n",
    "    './data/covers/validation',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    './data/covers/test',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# describe model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=10,\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "# compute loss and accuracy on test data\n",
    "score = model.evaluate(test_gen)\n",
    "# score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even with data augmentation we can not get a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Does it work better with grayscale images?\n",
    "Maybe it helps to leave out the color information of our images. We are going to load them as grayscale images and feed them into our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Pre-trained neural networks \n",
    "\n",
    "All our approaches did not get better results than the MNIST model with an accuracy of $0.312$. It seems that we have to look into pre-trained neural networks. Our first network is VGG16. VGG16 is a convolutional neutal network model. VGG16 was invented by K. Simonyan and A. Zisserman. They achieved an accuracy of $92.2%$ in ImageNet. ImageNet uses 14 million images belonging to 1000 classes. This network is trained on a large set and performed well. We will see how it performs with our task of classifying album covers.\n",
    "\n",
    "<cite>https://neurohive.io/en/popular-networks/vgg16/</cite>\n",
    "\n",
    "![alt text](./img/vgg16-neural-network.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         src categories\n",
      "2859        pop\\pop.341.jpeg      [pop]\n",
      "3219        pop\\pop.902.jpeg      [pop]\n",
      "1551  hiphop\\hiphop.718.jpeg   [hiphop]\n",
      "1289  hiphop\\hiphop.460.jpeg   [hiphop]\n",
      "2045      jazz\\jazz.326.jpeg     [jazz]\n",
      "...                      ...        ...\n",
      "3810      rock\\rock.675.jpeg     [rock]\n",
      "2772        pop\\pop.200.jpeg      [pop]\n",
      "3369       rock\\rock.18.jpeg     [rock]\n",
      "1011  hiphop\\hiphop.171.jpeg   [hiphop]\n",
      "1097  hiphop\\hiphop.272.jpeg   [hiphop]\n",
      "\n",
      "[3276 rows x 2 columns]\n",
      "Found 3276 validated image filenames belonging to 5 classes.\n",
      "3276\n",
      "Found 410 validated image filenames belonging to 5 classes.\n",
      "Found 410 validated image filenames belonging to 5 classes.\n",
      "#######################################################################\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,813,381\n",
      "Trainable params: 2,098,693\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.6413 - accuracy: 0.2375 - val_loss: 0.5579 - val_accuracy: 0.2400\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.5508 - accuracy: 0.2590 - val_loss: 0.5398 - val_accuracy: 0.2550\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5318 - accuracy: 0.2846 - val_loss: 0.5595 - val_accuracy: 0.3400\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.5253 - accuracy: 0.3146 - val_loss: 0.5537 - val_accuracy: 0.2950\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.5256 - accuracy: 0.3141 - val_loss: 0.5318 - val_accuracy: 0.3000\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.5216 - accuracy: 0.3317 - val_loss: 0.5346 - val_accuracy: 0.3250\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.5116 - accuracy: 0.3377 - val_loss: 0.5180 - val_accuracy: 0.3700\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5139 - accuracy: 0.3375 - val_loss: 0.5271 - val_accuracy: 0.3300\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5075 - accuracy: 0.3567 - val_loss: 0.5371 - val_accuracy: 0.3300\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.5097 - accuracy: 0.3462 - val_loss: 0.5494 - val_accuracy: 0.3250\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.5097 - accuracy: 0.3382 - val_loss: 0.5236 - val_accuracy: 0.3900\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.5018 - accuracy: 0.3672 - val_loss: 0.5329 - val_accuracy: 0.3350\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5035 - accuracy: 0.3602 - val_loss: 0.5564 - val_accuracy: 0.3250\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.5010 - accuracy: 0.3768 - val_loss: 0.5184 - val_accuracy: 0.3650\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5020 - accuracy: 0.3675 - val_loss: 0.5413 - val_accuracy: 0.3600\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4984 - accuracy: 0.3592 - val_loss: 0.5506 - val_accuracy: 0.3650\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.4922 - accuracy: 0.3773 - val_loss: 0.5219 - val_accuracy: 0.3450\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.4899 - accuracy: 0.3838 - val_loss: 0.5350 - val_accuracy: 0.3350\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.4962 - accuracy: 0.3853 - val_loss: 0.5392 - val_accuracy: 0.3450\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4961 - accuracy: 0.3885 - val_loss: 0.5440 - val_accuracy: 0.3050\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4890 - accuracy: 0.3943 - val_loss: 0.5305 - val_accuracy: 0.3350\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.4889 - accuracy: 0.3853 - val_loss: 0.5401 - val_accuracy: 0.3650\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4837 - accuracy: 0.3985 - val_loss: 0.5360 - val_accuracy: 0.3750\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4853 - accuracy: 0.4038 - val_loss: 0.5408 - val_accuracy: 0.3300\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4797 - accuracy: 0.4050 - val_loss: 0.5105 - val_accuracy: 0.3300\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.4828 - accuracy: 0.3940 - val_loss: 0.5338 - val_accuracy: 0.3550\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4788 - accuracy: 0.4068 - val_loss: 0.5203 - val_accuracy: 0.4050\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.4700 - accuracy: 0.4314 - val_loss: 0.5474 - val_accuracy: 0.3750\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.4749 - accuracy: 0.4175 - val_loss: 0.5261 - val_accuracy: 0.3300\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.4778 - accuracy: 0.4085 - val_loss: 0.5314 - val_accuracy: 0.3850\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.4789 - accuracy: 0.4265 - val_loss: 0.5638 - val_accuracy: 0.3050\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4699 - accuracy: 0.4205 - val_loss: 0.5240 - val_accuracy: 0.3450\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.4674 - accuracy: 0.4379 - val_loss: 0.5430 - val_accuracy: 0.3350\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4684 - accuracy: 0.4299 - val_loss: 0.5491 - val_accuracy: 0.3150\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4692 - accuracy: 0.4374 - val_loss: 0.5378 - val_accuracy: 0.3550\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4714 - accuracy: 0.4145 - val_loss: 0.5519 - val_accuracy: 0.3450\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.4563 - accuracy: 0.4539 - val_loss: 0.5562 - val_accuracy: 0.3550\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.4638 - accuracy: 0.4400 - val_loss: 0.5998 - val_accuracy: 0.3600\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4661 - accuracy: 0.4360 - val_loss: 0.5454 - val_accuracy: 0.4250\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.4707 - accuracy: 0.4349 - val_loss: 0.5761 - val_accuracy: 0.3350\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4577 - accuracy: 0.4395 - val_loss: 0.5139 - val_accuracy: 0.3950\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4632 - accuracy: 0.4455 - val_loss: 0.5488 - val_accuracy: 0.3100\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4602 - accuracy: 0.4339 - val_loss: 0.5638 - val_accuracy: 0.3300\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4610 - accuracy: 0.4484 - val_loss: 0.5416 - val_accuracy: 0.3450\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4546 - accuracy: 0.4514 - val_loss: 0.5652 - val_accuracy: 0.3850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4581 - accuracy: 0.4385 - val_loss: 0.5753 - val_accuracy: 0.2950\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4550 - accuracy: 0.4384 - val_loss: 0.5739 - val_accuracy: 0.3550\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.4557 - accuracy: 0.4559 - val_loss: 0.5373 - val_accuracy: 0.3900\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.4579 - accuracy: 0.4410 - val_loss: 0.5415 - val_accuracy: 0.3800\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4553 - accuracy: 0.4429 - val_loss: 0.5679 - val_accuracy: 0.3850\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.5716 - accuracy: 0.3463\n",
      "Test score: 0.5716409683227539\n",
      "Test accuracy: 0.34634146094322205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('./data/df.csv', index_col=0)\n",
    "df['categories']=df['categories'].apply(lambda x:x.split(\",\"))\n",
    "\n",
    "df = shuffle(df)\n",
    "df_train, df_test, df_validate = np.split(df, [int(len(df)*PERC_TRAIN), int(len(df)*(1.0-PERC_VALIDATE))])\n",
    "\n",
    "print(df_train)\n",
    "BATCH_SIZE = 20\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_gen = training_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    directory='./data/covers_original',\n",
    "    x_col='src',\n",
    "    y_col='categories',\n",
    "    #class_mode='categorical',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=CATEGORIES,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(train_gen.n)\n",
    "\n",
    "\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_dataframe(\n",
    "    df_validate,\n",
    "    directory='./data/covers_original',\n",
    "    x_col='src',\n",
    "    y_col='categories',\n",
    "#     class_mode='categorical',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=CATEGORIES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "    df_test,\n",
    "    directory='./data/covers_original',\n",
    "    x_col='src',\n",
    "    y_col='categories',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "#     class_mode=None,\n",
    "    classes=CATEGORIES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "print(\"#######################################################################\")\n",
    "\n",
    "# download VGG16 model for image classification\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# define the architecture of the neural network building on VGG15\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='sigmoid'))\n",
    "conv_base.trainable = False\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=10,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "# compute loss and accuracy on test data\n",
    "score = model.evaluate(test_gen)\n",
    "# score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19 \n",
    "\n",
    "After VGG16 we give VGG19 a try. As the name suggests, VGG19 has 19 Layers. It can be used like VGG16 from the Keras library. For more supported pre trained neural networks have a look at the docs. (https://keras.io/api/applications/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 src         categories\n",
      "1695          hiphop\\hiphop.863.jpeg           [hiphop]\n",
      "2838                pop\\pop.303.jpeg              [pop]\n",
      "1756          hiphop\\hiphop.924.jpeg           [hiphop]\n",
      "1267           hiphop\\hiphop.44.jpeg     [hiphop, jazz]\n",
      "3919              rock\\rock.797.jpeg             [rock]\n",
      "...                              ...                ...\n",
      "2318              jazz\\jazz.615.jpeg             [jazz]\n",
      "977           hiphop\\hiphop.130.jpeg     [hiphop, jazz]\n",
      "3102                pop\\pop.739.jpeg              [pop]\n",
      "131   electronic\\electronic.216.jpeg  [electronic, pop]\n",
      "1538          hiphop\\hiphop.705.jpeg           [hiphop]\n",
      "\n",
      "[3276 rows x 2 columns]\n",
      "Found 3276 validated image filenames belonging to 5 classes.\n",
      "3276\n",
      "Found 410 validated image filenames belonging to 5 classes.\n",
      "Found 410 validated image filenames belonging to 5 classes.\n",
      "#######################################################################\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 22,123,077\n",
      "Trainable params: 2,098,693\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6933 - accuracy: 0.2290 - val_loss: 0.5917 - val_accuracy: 0.2250\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.5561 - accuracy: 0.2570 - val_loss: 0.5521 - val_accuracy: 0.3000\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.5381 - accuracy: 0.2871 - val_loss: 0.5233 - val_accuracy: 0.2800\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.5329 - accuracy: 0.2925 - val_loss: 0.5306 - val_accuracy: 0.3150\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.5263 - accuracy: 0.3135 - val_loss: 0.5301 - val_accuracy: 0.2600\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.5230 - accuracy: 0.3186 - val_loss: 0.5346 - val_accuracy: 0.3000\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.5207 - accuracy: 0.3400 - val_loss: 0.5129 - val_accuracy: 0.3150\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.5195 - accuracy: 0.3325 - val_loss: 0.5225 - val_accuracy: 0.2850\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.5162 - accuracy: 0.3380 - val_loss: 0.5267 - val_accuracy: 0.2750\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.5122 - accuracy: 0.3387 - val_loss: 0.5312 - val_accuracy: 0.2950\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.5039 - accuracy: 0.3567 - val_loss: 0.5278 - val_accuracy: 0.2900\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.5120 - accuracy: 0.3552 - val_loss: 0.5373 - val_accuracy: 0.2450\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.5021 - accuracy: 0.3612 - val_loss: 0.5369 - val_accuracy: 0.2850\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.4988 - accuracy: 0.3853 - val_loss: 0.5482 - val_accuracy: 0.2800\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.5032 - accuracy: 0.3747 - val_loss: 0.5694 - val_accuracy: 0.2650\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.5050 - accuracy: 0.3687 - val_loss: 0.5313 - val_accuracy: 0.3050\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.5016 - accuracy: 0.3605 - val_loss: 0.5411 - val_accuracy: 0.2900\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.5014 - accuracy: 0.3775 - val_loss: 0.5279 - val_accuracy: 0.2950\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.4990 - accuracy: 0.3805 - val_loss: 0.5513 - val_accuracy: 0.3000\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.5017 - accuracy: 0.3863 - val_loss: 0.5634 - val_accuracy: 0.3000\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 0.5389 - accuracy: 0.2927\n",
      "Test score: 0.5389195680618286\n",
      "Test accuracy: 0.2926829159259796\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/df.csv', index_col=0)\n",
    "df['categories']=df['categories'].apply(lambda x:x.split(\",\"))\n",
    "\n",
    "df = shuffle(df)\n",
    "df_train, df_test, df_validate = np.split(df, [int(len(df)*PERC_TRAIN), int(len(df)*(1.0-PERC_VALIDATE))])\n",
    "\n",
    "print(df_train)\n",
    "BATCH_SIZE = 20\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_gen = training_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    directory='./data/covers_original',\n",
    "    x_col='src',\n",
    "    y_col='categories',\n",
    "    #class_mode='categorical',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=CATEGORIES,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(train_gen.n)\n",
    "\n",
    "\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_dataframe(\n",
    "    df_validate,\n",
    "    directory='./data/covers_original',\n",
    "    x_col='src',\n",
    "    y_col='categories',\n",
    "#     class_mode='categorical',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=CATEGORIES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "    df_test,\n",
    "    directory='./data/covers_original',\n",
    "    x_col='src',\n",
    "    y_col='categories',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "#     class_mode=None,\n",
    "    classes=CATEGORIES,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "print(\"#######################################################################\")\n",
    "\n",
    "# download VGG16 model for image classification\n",
    "conv_base = VGG19(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# define the architecture of the neural network building on VGG15\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='sigmoid'))\n",
    "conv_base.trainable = False\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=10,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "# compute loss and accuracy on test data\n",
    "score = model.evaluate(test_gen)\n",
    "# score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Own Approaches\n",
    "\n",
    "Since our results are between 0.2 and 0.35 accuracy we have a general thesis about the problem of classifying album covers.\n",
    "The covers in one genre don¬¥t have enough similarities. So our network can not find features specific to one genre and then calssify it. The second drawback is that the genre have similar 'features'. For example every genre has some cover with human faces on. Our next step will be to select 2 most divers classes and then train a "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
